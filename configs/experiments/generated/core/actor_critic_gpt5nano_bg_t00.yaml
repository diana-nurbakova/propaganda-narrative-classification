# Experiment Configuration
# Model: GPT-5-nano
# Method: Actor-Critic (validation)
# Strategy: Level-First (DL)
# Language: BG
# Temperature: 0.0
#
# Generated by generate_configs.py
# Use with run_multi_experiment.py for statistical testing

model_name: openai:gpt-5-nano
input_folder: data/dev-documents_4_December/BG/subtask-2-documents/
output_file: results/experiments/actor_critic_gpt5nano_bg_t00/run_{run_id}/results.txt
temperature: 0.0
top_p: 1.0
max_tokens: 16384
hierarchical_strategy: level_first
num_narrative_agents: 1
num_subnarrative_agents: 1
narrative_aggregation_method: union
subnarrative_aggregation_method: union
enable_validation: true
enable_narrative_validation: true
enable_subnarrative_validation: true
enable_retrieval: false
enable_cleaning: true
enable_text_cleaning: false
max_concurrency: 3
enable_cost_tracking: true
cost_metrics_path: results/experiments/actor_critic_gpt5nano_bg_t00/run_{run_id}/cost_metrics.json
