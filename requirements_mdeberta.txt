# Minimal requirements for mDeBERTa fine-tuning only
torch>=2.0.0
transformers>=4.40.0
datasets>=3.0.0
accelerate>=0.30.0
scikit-learn>=1.3.0
pandas>=2.0.0
numpy>=1.24.0
sentencepiece>=0.2.0
protobuf>=4.0.0
tiktoken>=0.5.0
tqdm>=4.60.0
safetensors>=0.4.0
huggingface-hub>=0.20.0
